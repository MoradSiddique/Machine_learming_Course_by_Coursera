# Machine_learming_Course_by_Coursera

This course provides a broad introduction to machine learning, datamining, and statistical pattern recognition.
Topics include:
(i) Supervised learning (parametric/non-parametric algorithms, support vector machines, kernels, neural networks).
(ii) Unsupervised learning (clustering, dimensionality reduction, recommender systems, deep learning).
(iii) Best practices in machine learning (bias/variance theory; innovation process in machine learning and AI). The course will also draw from numerous case studies and applications, so that you'll also learn how to apply learning algorithms to building smart robots (perception, control), text understanding (web search, anti-spam), computer vision, medical informatics, audio, database mining, and other areas.


 This course about supervised learning algorithms like linear regression, logistic regression, neural networks, SVMs. for problems where  have labelled data and labelled examples like x(i), y(i) And also about unsupervised learning like K-means clustering, Principal Components Analysis for dimensionality reduction and Anomaly Detection algorithms for when only unlabelled data x(i) Although Anomaly Detection can also use some labelled data to evaluate the algorithm. We also spent some time talking about special applications or special topics like Recommender Systems and large scale machine learning systems including parallelized and rapid-use systems as well as some special applications like sliding windows object classification for computer vision. And finally also about different aspects of, sort of, advice on building a machine learning system. And this involved both trying to understand what is it that makes a machine learning algorithm work or not work. About things like bias and variance, and how regularization can help with some variance problems. And also about this question of how to decide what to work on next. So, how to prioritize how to developing a machine learning system. About evaluation of learning algorithms, evaluation metrics like precision recall, F1 score as well as practical aspects of evaluation like the training, cross-validation and test sets. And About debugging learning algorithms and making sure the learning algorithm is working.About diagnostics like learning curves and also about things like error analysis and ceiling analysis.
